"""
Scraper HTTP optimizado para reemplazar Selenium en casos simples
Usa requests + BeautifulSoup para mayor velocidad y menos recursos
"""
import requests
from bs4 import BeautifulSoup
import logging
import time
import random
from typing import List, Optional
import re

logger = logging.getLogger(__name__)

class HTTPScraper:
    def __init__(self):
        """Inicializar scraper HTTP optimizado para hosting web"""
        self.session = requests.Session()

        # Headers optimizados para hosting web sin VNC
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Cache-Control': 'no-cache',
            'Pragma': 'no-cache'
        })

        # Configurar timeouts optimizados para hosting web
        self.session.timeout = (10, 30)  # (connect, read)

        logger.info("‚úÖ HTTP Scraper inicializado para hosting web sin VNC")

    def get_game_servers_fast(self, game_id: str, max_servers: int = 5) -> List[str]:
        """
        Obtener servidores usando HTTP requests (m√°s r√°pido que Selenium)
        """
        try:
            url = f"https://rbxservers.xyz/games/{game_id}"
            logger.info(f"üåê HTTP Scraping: {url}")

            # Hacer request a la p√°gina principal del juego
            response = self.session.get(url, timeout=10)
            response.raise_for_status()

            # Parsear HTML
            soup = BeautifulSoup(response.text, 'html.parser')

            # Buscar enlaces de servidores
            server_links = []

            # Buscar enlaces que apunten a p√°ginas de servidores individuales
            for link in soup.find_all('a', href=True):
                href = link['href']
                if '/servers/' in href and href.startswith('/'):
                    full_server_url = f"https://rbxservers.xyz{href}"
                    server_links.append(full_server_url)

                    if len(server_links) >= max_servers:
                        break

            logger.info(f"‚úÖ Encontrados {len(server_links)} enlaces de servidores")
            return server_links

        except Exception as e:
            logger.error(f"‚ùå Error en HTTP scraping: {e}")
            return []

    def extract_vip_link_fast(self, server_url: str) -> Optional[str]:
        """
        Extraer link VIP de una p√°gina de servidor usando HTTP
        """
        try:
            logger.debug(f"üîç Extrayendo VIP de: {server_url}")

            # Peque√±a pausa para no saturar el servidor
            time.sleep(random.uniform(0.5, 1.5))

            response = self.session.get(server_url, timeout=15)
            response.raise_for_status()

            # Buscar el link VIP en el HTML
            soup = BeautifulSoup(response.text, 'html.parser')

            # Buscar input con valor que contenga roblox.com/games
            vip_inputs = soup.find_all('input', {'type': 'text'})
            for input_tag in vip_inputs:
                value = input_tag.get('value', '')
                if 'roblox.com/games' in value and 'privateServerLinkCode' in value:
                    logger.debug(f"‚úÖ VIP link encontrado: {value[:50]}...")
                    return value

            # Buscar tambi√©n en el c√≥digo JavaScript o texto
            script_tags = soup.find_all('script')
            for script in script_tags:
                if script.string:
                    # Buscar patrones de links VIP en JavaScript
                    vip_pattern = r'https://www\.roblox\.com/games/\d+\?privateServerLinkCode=[A-Za-z0-9\-_]+'
                    matches = re.findall(vip_pattern, script.string)
                    if matches:
                        logger.debug(f"‚úÖ VIP link en JS: {matches[0][:50]}...")
                        return matches[0]

            logger.debug(f"‚ö†Ô∏è No se encontr√≥ VIP link en: {server_url}")
            return None

        except Exception as e:
            logger.error(f"‚ùå Error extrayendo VIP link: {e}")
            return None

    def scrape_game_fast(self, game_id: str, max_servers: int = 5) -> List[str]:
        """
        Scraping completo de un juego usando solo HTTP
        """
        try:
            logger.info(f"üöÄ Iniciando HTTP scraping r√°pido para juego {game_id}")
            start_time = time.time()

            # Obtener enlaces de servidores
            server_urls = self.get_game_servers_fast(game_id, max_servers)

            if not server_urls:
                logger.warning(f"‚ö†Ô∏è No se encontraron servidores para {game_id}")
                return []

            # Extraer VIP links
            vip_links = []
            for server_url in server_urls:
                vip_link = self.extract_vip_link_fast(server_url)
                if vip_link:
                    vip_links.append(vip_link)

                # L√≠mite de tiempo para evitar que tome demasiado
                if time.time() - start_time > 30:  # 30 segundos m√°ximo
                    logger.warning("‚è∞ Tiempo l√≠mite alcanzado en HTTP scraping")
                    break

            duration = time.time() - start_time
            logger.info(f"‚úÖ HTTP Scraping completado: {len(vip_links)} VIP links en {duration:.1f}s")

            return vip_links

        except Exception as e:
            logger.error(f"‚ùå Error en scraping r√°pido: {e}")
            return []

    def close(self):
        """Cerrar sesi√≥n HTTP"""
        self.session.close()

def setup_commands(bot):
    """
    Configurar comando de scraping HTTP optimizado
    """

    @bot.tree.command(name="fastscrape", description="Scraping ultra r√°pido usando HTTP (experimental)")
    async def fastscrape_command(interaction, game_id: str):
        """Scraping r√°pido sin Selenium"""
        user_id = str(interaction.user.id)

        # Verificar autenticaci√≥n
        from main import check_verification
        if not await check_verification(interaction, defer_response=True):
            return

        try:
            # Crear scraper HTTP
            http_scraper = HTTPScraper()

            # Info inicial
            embed = discord.Embed(
                title="‚ö° Fast Scrape Iniciado",
                description=f"Probando scraping HTTP para juego `{game_id}`",
                color=0x00aaff
            )
            message = await interaction.followup.send(embed=embed, ephemeral=True)

            # Ejecutar scraping
            vip_links = http_scraper.scrape_game_fast(game_id, max_servers=3)

            if vip_links:
                # Mostrar resultados
                links_text = "\n".join([f"‚Ä¢ {link}" for link in vip_links])

                result_embed = discord.Embed(
                    title="‚úÖ Fast Scrape Completado",
                    description=f"**{len(vip_links)}** servidores encontrados usando HTTP",
                    color=0x00ff88
                )
                result_embed.add_field(
                    name="üîó Servidores VIP:",
                    value=f"```{links_text}```",
                    inline=False
                )
                result_embed.add_field(
                    name="‚ö° Ventajas HTTP:",
                    value="‚Ä¢ 5x m√°s r√°pido que Selenium\n‚Ä¢ Menos uso de recursos\n‚Ä¢ No requiere navegador",
                    inline=False
                )

                await message.edit(embed=result_embed)
            else:
                error_embed = discord.Embed(
                    title="‚ùå Sin Resultados",
                    description="No se encontraron servidores con el m√©todo HTTP",
                    color=0xff0000
                )
                await message.edit(embed=error_embed)

            # Limpiar
            http_scraper.close()

        except Exception as e:
            logger.error(f"Error en fastscrape: {e}")
            error_embed = discord.Embed(
                title="‚ùå Error",
                description="Error en el scraping HTTP",
                color=0xff0000
            )
            await interaction.followup.send(embed=error_embed, ephemeral=True)

    logger.info("‚ö° Comando HTTP Fast Scrape configurado")
    return True